{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9d5506",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40585506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 경로\n",
    "DATA_PATH = '/aiffel/aiffel/fnguide/data/'\n",
    "\n",
    "# 데이터 불러오기\n",
    "modify_data = pd.read_csv(os.path.join(DATA_PATH, 'sub_upbit_eth_min_tick.csv'), index_col=0, parse_dates=True)\n",
    "\n",
    "# 불러온 데이터 시각화하기\n",
    "modify_data.loc['2017-11-01':'2017-12-31','close'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50221646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# window 지정\n",
    "window = 10\n",
    "\n",
    "# momentum_signal 만들기\n",
    "momentum_signal = np.sign(modify_data['close'] - modify_data['close'].shift(window))\n",
    "\n",
    "# s_momentum_signal 만들기\n",
    "s_momentum_signal = pd.Series(momentum_signal, index=modify_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acec46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 데이터 만들기\n",
    "# loc를 활용하여 2017-11-21부터 close(종가)까지 가져오기\n",
    "sub_data = modify_data.loc['2017-11-21':, 'close']\n",
    "\n",
    "# 수식 적용된 데이터(Signal) 만들기\n",
    "# loc를 활용하여 2017-11-21의 시간대별 값을 가져오기 (데이터프레임으로 변환하여 색상 컬럼 추가 준비)\n",
    "c_sig = s_momentum_signal.loc['2017-11-21':].to_frame(name='signal')\n",
    "\n",
    "# 두 데이터의 비교를 위한 색상 바꾸기\n",
    "# np.where 사용: 시그널이 0보다 크면(상승) 'red', 아니면 'blue'\n",
    "c_sig['color'] = np.where(c_sig['signal'] > 0, 'red', 'blue')\n",
    "\n",
    "# 시각화하기\n",
    "plt.figure(figsize=(15, 5))\n",
    "# 주가 선 그래프 그리기\n",
    "plt.plot(sub_data.index, sub_data, label='Close Price', alpha=0.5)\n",
    "# 시그널에 따른 산점도 그리기 (상승: 빨강, 하락: 파랑)\n",
    "plt.scatter(sub_data.index, sub_data, c=c_sig['color'], s=20, label='Signal')\n",
    "\n",
    "plt.title(f'Price Change Direction (Window={window})')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bca6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# momentum_signal\n",
    "# 주가가 이동평균보다 높으면 양수(+), 낮으면 음수(-)가 나오도록 차이를 계산\n",
    "momentum_signal = np.sign(modify_data['close'] - modify_data['close'].rolling(window).mean())\n",
    "\n",
    "# s_momentum_signal\n",
    "s_momentum_signal = pd.Series(momentum_signal, index=modify_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88322901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 데이터 만들기\n",
    "# 2017-11-21부터 종가 데이터 가져오기\n",
    "sub_data = modify_data.loc['2017-11-21':, 'close']\n",
    "\n",
    "# 수식 적용된 데이터 만들기\n",
    "# 시그널 데이터를 가져와서 데이터프레임으로 변환 (색상 컬럼 추가를 위해)\n",
    "c_sig = s_momentum_signal.loc['2017-11-21':].to_frame(name='signal')\n",
    "\n",
    "# 두 데이터의 비교를 위한 색상 바꾸기\n",
    "# 시그널이 0보다 크면(주가 > 이동평균) 'red', 아니면 'blue'\n",
    "c_sig['color'] = np.where(c_sig['signal'] > 0, 'red', 'blue')\n",
    "\n",
    "# 시각화하기\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# 1. 주가 선 그래프\n",
    "plt.plot(sub_data.index, sub_data, label='Close Price', alpha=0.5)\n",
    "\n",
    "# 2. 이동평균선 (시각적 이해를 돕기 위해 추가)\n",
    "ma_data = modify_data['close'].rolling(window).mean().loc['2017-11-21':]\n",
    "plt.plot(ma_data.index, ma_data, label=f'Moving Average ({window})', linestyle='--', color='orange')\n",
    "\n",
    "# 3. 시그널 산점도\n",
    "plt.scatter(sub_data.index, sub_data, c=c_sig['color'], s=20, label='Signal')\n",
    "\n",
    "plt.title(f'Labeling: Using Moving Average (Window={window})')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7bb111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local min / max 를 추출하기 위한 함수\n",
    "def get_local_min_max(close, wait=3):\n",
    "    min_value = close.iloc[0]\n",
    "    max_value = close.iloc[0]  # ① 초기값 설정\n",
    "    n_cnt_min, n_cnt_max = 0, 0\n",
    "    \n",
    "    mins, maxes = [], []\n",
    "    min_idxes, max_idxes = [], []\n",
    "    b_min_update, b_max_update = False, False\n",
    "    \n",
    "    for idx, val in zip(close.index[1:], close.values[1:]):\n",
    "        # 최저값 갱신 로직\n",
    "        if val < min_value:\n",
    "            min_value = val\n",
    "            mins.append(min_value)\n",
    "            min_idxes.append(idx)\n",
    "            n_cnt_min = 0\n",
    "            b_min_update = True\n",
    "            \n",
    "        # 최고값 갱신 로직\n",
    "        if val > max_value:\n",
    "            max_value = val  # ② 값 갱신\n",
    "            maxes.append(max_value)  # ③ 리스트에 추가\n",
    "            max_idxes.append(idx)\n",
    "            n_cnt_max = 0\n",
    "            b_max_update = True  # ④ 플래그 업데이트 (최고점 갱신됨)\n",
    "        \n",
    "        # 최고점이 갱신되지 않았을 때 (하락세 혹은 횡보 중일 때 최저점 로직 체크)\n",
    "        if not b_max_update:\n",
    "            b_min_update = False\n",
    "            n_cnt_min += 1\n",
    "            if n_cnt_min >= wait:\n",
    "                max_value = min_value # 고점을 현재 저점으로 초기화 (추세 반전 감지용)\n",
    "                n_cnt_min = 0\n",
    "    \n",
    "        # 최저점이 갱신되지 않았을 때 (상승세 혹은 횡보 중일 때 최고점 로직 체크)\n",
    "        if not b_min_update:\n",
    "            b_max_update = False  # ⑤ 플래그 초기화\n",
    "            n_cnt_max += 1        # ⑥ 카운트 증가\n",
    "            if n_cnt_max >= wait:\n",
    "                min_value = max_value  # ⑦ 저점을 현재 고점으로 초기화\n",
    "                n_cnt_max = 0\n",
    "                \n",
    "    # ⑧ 결과 반환 (시각화를 위해 DataFrame으로 변환하여 반환)\n",
    "    return pd.DataFrame(mins, index=min_idxes, columns=['min']), pd.DataFrame(maxes, index=max_idxes, columns=['max'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabcf130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local mins, maxes를 확인\n",
    "mins, maxes = get_local_min_max(sub_data, wait=3)\n",
    "\n",
    "# mins, maxes 확인 \n",
    "print(mins)\n",
    "print('--'*20)\n",
    "print(maxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e894817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subplots 및 plot 생성\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5)) # 적절한 사이즈 설정\n",
    "ax.plot(sub_data, 'c', alpha=0.6) # 원본 데이터 (청록색)\n",
    "\n",
    "# min_time, local_min을 활용한 scatter plot 생성\n",
    "# 저점(매수 포인트)은 빨간색 점으로 표시\n",
    "ax.scatter(mins.index, mins['min'], c='r', s=30, label='Local Min', zorder=2)\n",
    "\n",
    "# maxes_time, local_max를 활용한 scatter plot 생성\n",
    "# 고점(매도 포인트)은 파란색 점으로 표시\n",
    "ax.scatter(maxes.index, maxes['max'], c='b', s=30, label='Local Max', zorder=2)\n",
    "\n",
    "# y축 설정\n",
    "ax.set_ylim([sub_data.min() * 0.99, sub_data.max() * 1.01])\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8935ff3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_val_lin_r(close):\n",
    "    import statsmodels.api as sml\n",
    "    \n",
    "    # t-value from a linear trend\n",
    "    x = np.ones((close.shape[0], 2))\n",
    "    x[:, 1] = np.arange(close.shape[0])\n",
    "    ols = sml.OLS(close, x).fit() \n",
    "    return ols.tvalues[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd510314",
   "metadata": {},
   "outputs": [],
   "source": [
    "look_forward_window = 60\n",
    "min_sample_length = 5\n",
    "step = 1\n",
    "t1_array = []\n",
    "t_values_array = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728a9c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sml\n",
    "\n",
    "molecule = modify_data['2017-11-01':'2017-11-30'].index\n",
    "label = pd.DataFrame(index=molecule, columns=['t1', 't_val', 'bin'])\n",
    "tmp_out = []\n",
    "\n",
    "for ind in tqdm(molecule):\n",
    "    subset = modify_data.loc[ind:, 'close'].iloc[:look_forward_window]  # 전방 탐색을 위한 샘플 추출\n",
    "    if look_forward_window > subset.shape[0]:\n",
    "        continue\n",
    "\n",
    "    tmp_subset = pd.Series(index=subset.index[min_sample_length-1:subset.shape[0]-1])\n",
    "    tval = []\n",
    "\n",
    "    # 회귀분석을 통해 t 통계량값을 이용하여 추세 추정\n",
    "    for forward_window in np.arange(min_sample_length, subset.shape[0]):\n",
    "        df = subset.iloc[:forward_window]\n",
    "        # ① 해당 구간의 t-value 계산하여 리스트에 추가\n",
    "        tval.append(t_val_lin_r(df))\n",
    "\n",
    "    # 계산된 t-value들을 Series에 할당\n",
    "    tmp_subset.loc[tmp_subset.index] = np.array(tval)\n",
    "\n",
    "    # t-value의 절대값이 가장 큰(가장 강력한 추세인) 시점 찾기\n",
    "    idx_max = tmp_subset.replace([-np.inf, np.inf, np.nan], 0).abs().idxmax()\n",
    "    tmp_t_val = tmp_subset[idx_max]\n",
    "\n",
    "    # 결과 저장: [추세 종료 시점, t-value값, 라벨(1 or -1)]\n",
    "    tmp_out.append([tmp_subset.index[-1], tmp_t_val, np.sign(tmp_t_val)])\n",
    "\n",
    "# ② 결과 리스트를 DataFrame에 할당\n",
    "label.loc[molecule] = np.array(tmp_out)  # prevent leakage\n",
    "\n",
    "label['t1'] = pd.to_datetime(label['t1'])\n",
    "label['bin'] = pd.to_numeric(label['bin'], downcast='signed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e546e87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화\n",
    "sub_data = modify_data.loc['2017-11-21', 'close']\n",
    "c_sig = label['bin'].loc['2017-11-21']\n",
    "c_sig['color'] = np.where(c_sig == 1, 'red', 'blue')\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "ax.scatter(sub_data.index, sub_data.values, c=c_sig['color'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deea66d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ta==0.9.0\n",
    "!pip install shap\n",
    "!pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c895fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import io\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ta\n",
    "\n",
    "import sys\n",
    "sys.path.append('/aiffel/aiffel/fnguide/data/')\n",
    "from libs.feature_importance import importance as imp\n",
    "from sklearn.feature_selection import SequentialFeatureSelector, RFECV\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b20dba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 경로 설정\n",
    "DATA_PATH = '/aiffel/aiffel/fnguide/data/'\n",
    "anno_file_name = os.path.join(DATA_PATH, 'sub_upbit_eth_min_tick_label.pkl')\n",
    "target_file_name = os.path.join(DATA_PATH, 'sub_upbit_eth_min_tick.csv')\n",
    "\n",
    "# 데이터 불러오기\n",
    "df_modify_data = pd.read_csv(target_file_name, index_col=0, parse_dates=True)\n",
    "df_label_data = pd.read_pickle(anno_file_name)\n",
    "df_sub_modify_data = df_modify_data.loc[df_label_data.index]\n",
    "\n",
    "# 학습 시간 단축을 위해 여기선 편의상 1000개의 데이터만 가져옵니다.\n",
    "df_sub_modify_data = df_sub_modify_data.iloc[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd27ea6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기술적 지표를 적용합니다.\n",
    "\n",
    "mt = 1\n",
    "fillna = False\n",
    "df_ = df_sub_modify_data.copy()\n",
    "open, high, low, close, volume = 'open', 'high', 'low', 'close', 'volume'\n",
    "cols = [open, high, low, close, volume]\n",
    "\n",
    "## Volume Index\n",
    "# Chaikin Money Flow\n",
    "df_[\"volume_cmf\"] = ta.volume.ChaikinMoneyFlowIndicator(\n",
    "                        high=df_[high], low=df_[low], close=df_[close], volume=df_[volume], window=20*mt, fillna=fillna\n",
    "                    ).chaikin_money_flow()\n",
    "# Force Index\n",
    "df_[\"volume_fi\"] = ta.volume.ForceIndexIndicator(\n",
    "                        close=df_[close], volume=df_[volume], window=15*mt, fillna=fillna\n",
    "                    ).force_index()\n",
    "# Money Flow Indicator\n",
    "df_[\"volume_mfi\"] = ta.volume.MFIIndicator(\n",
    "                        high=df_[high],\n",
    "                        low=df_[low],\n",
    "                        close=df_[close],\n",
    "                        volume=df_[volume],\n",
    "                        window=15*mt,\n",
    "                        fillna=fillna,\n",
    "                    ).money_flow_index()\n",
    "# Ease of Movement\n",
    "df_[\"volume_sma_em\"] = ta.volume.EaseOfMovementIndicator(\n",
    "                            high=df_[high], low=df_[low], volume=df_[volume], window=15*mt, fillna=fillna\n",
    "                        ).sma_ease_of_movement()\n",
    "\n",
    "# Volume Price Trend\n",
    "df_[\"volume_vpt\"] = ta.volume.VolumePriceTrendIndicator(\n",
    "                        close=df_[close], volume=df_[volume], fillna=fillna\n",
    "                    ).volume_price_trend()\n",
    "\n",
    "## volatility index\n",
    "# Average True Range\n",
    "df_[\"volatility_atr\"] = ta.volatility.AverageTrueRange(\n",
    "                            close=df_[close], high=df_[high], low=df_[low], window=10*mt, fillna=fillna\n",
    "                        ).average_true_range()\n",
    "\n",
    "# Ulcer Index\n",
    "df_[\"volatility_ui\"] = ta.volatility.UlcerIndex(\n",
    "                            close=df_[close], window=15*mt, fillna=fillna\n",
    "                        ).ulcer_index()\n",
    "\n",
    "## trend index\n",
    "# MACD\n",
    "df_[\"trend_macd_diff\"] = ta.trend.MACD(\n",
    "                            close=df_[close], window_slow=25*mt, window_fast=10*mt, window_sign=9, fillna=fillna\n",
    "                        ).macd_diff()\n",
    "\n",
    "# Average Directional Movement Index (ADX)\n",
    "df_[\"trend_adx\"] = ta.trend.ADXIndicator(\n",
    "                        high=df_[high], low=df_[low], close=df_[close], window=15*mt, fillna=fillna\n",
    "                    ).adx()\n",
    "\n",
    "# TRIX Indicator\n",
    "df_[\"trend_trix\"] = ta.trend.TRIXIndicator(\n",
    "                        close=df_[close], window=15*mt, fillna=fillna\n",
    "                    ).trix()\n",
    "\n",
    "# Mass Index\n",
    "df_[\"trend_mass_index\"] = ta.trend.MassIndex(\n",
    "                            high=df_[high], low=df_[low], window_fast=10*mt, window_slow=25*mt, fillna=fillna\n",
    "                        ).mass_index()\n",
    "\n",
    "# DPO Indicator\n",
    "df_[\"trend_dpo\"] = ta.trend.DPOIndicator(\n",
    "                        close=df_[close], window=20*mt, fillna=fillna\n",
    "                    ).dpo()\n",
    "\n",
    "# Aroon Indicator\n",
    "df_[\"trend_aroon_ind\"] = ta.trend.AroonIndicator(close=df_[close], window=20, fillna=fillna).aroon_indicator()\n",
    "\n",
    "## momentum index\n",
    "# Relative Strength Index (RSI)\n",
    "df_[\"momentum_rsi\"] = ta.momentum.RSIIndicator(close=df_[close], window=15*mt, fillna=fillna).rsi()\n",
    "\n",
    "# Williams R Indicator\n",
    "df_[\"momentum_wr\"] = ta.momentum.WilliamsRIndicator(\n",
    "                        high=df_[high], low=df_[low], close=df_[close], lbp=15*mt, fillna=fillna\n",
    "                    ).williams_r()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6159b5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수익률 / 변동성 지표를 적용합니다.\n",
    "windows_mom = [5, 10, 20]\n",
    "windows_std = [30]\n",
    "\n",
    "for i in windows_mom:\n",
    "    df_[f'vol_change_{i}'] = df_.volume.pct_change(i).round(6)\n",
    "    df_[f'ret_{i}'] = df_.close.pct_change(i).round(6)\n",
    "\n",
    "for i in windows_std:\n",
    "    df_[f'std_{i}'] = df_.close.rolling(i).std()\n",
    "    df_[f'vol_std_{i}'] = df_.volume.rolling(i).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5661ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_label_data는 프로젝트 1에서 만든 라벨 데이터(예: Trend Scanning 결과)라고 가정합니다.\n",
    "# df_tmp_data는 기술적 지표가 추가된 데이터(df_)와 라벨 데이터(df_label_data)를 합치고 결측치를 제거한 데이터프레임입니다.\n",
    "df_tmp_data = df_.join(df_label_data).dropna()\n",
    "\n",
    "# X, y 데이터셋 만들기\n",
    "# X는 기술적 지표들이 있는 컬럼들 (5번째 컬럼부터 마지막 전까지)\n",
    "# y는 라벨이 있는 마지막 컬럼\n",
    "X = df_tmp_data.iloc[:, 5:-1] \n",
    "y = df_tmp_data.iloc[:, -1] # 라벨 데이터\n",
    "\n",
    "# StandardScaler 적용\n",
    "# 데이터의 스케일(단위)을 맞추기 위해 표준화(평균 0, 분산 1)를 진행합니다.\n",
    "sc = StandardScaler()\n",
    "\n",
    "# fit_transform 사용\n",
    "# X 데이터를 표준화 변환합니다.\n",
    "X_sc = sc.fit_transform(X)\n",
    "\n",
    "# DataFrame 변환\n",
    "# 변환된 numpy 배열을 다시 DataFrame으로 만들어서 컬럼명을 유지합니다.\n",
    "X_sc = pd.DataFrame(X_sc, index=X.index, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b0bf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest 모델 적용\n",
    "# 특성 중요도를 뽑아내기 위해 랜덤 포레스트 분류기를 사용\n",
    "# random_state를 고정하여 결과의 재현성을 확보\n",
    "rfc = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "\n",
    "# RandomForest fit\n",
    "rfc.fit(X_sc, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732f85d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MDI, Mean Decrease Impurity \n",
    "feat_imp = imp.mean_decrease_impurity(rfc, X.columns)\n",
    "feat_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd2b5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MDA, Mean Decrease Accuracy\n",
    "svc_rbf = SVC(kernel='rbf', probability=True) # Tree 및 Support Vector Machine 외에 다른 분류기(classifier)를 사용해봅시다.\n",
    "cv = KFold(n_splits=5) # n_splits을 변경해봅시다.\n",
    "feat_imp_mda = imp.mean_decrease_accuracy(svc_rbf, X_sc, y, cv_gen=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98878c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_feature_importance 함수 만들기\n",
    "def plot_feature_importance(importance_df, save_fig=False, output_path=None):\n",
    "    # Plot mean imp bars with std\n",
    "    plt.figure(figsize=(10, importance_df.shape[0] / 5))\n",
    "    importance_df.sort_values('mean', ascending=True, inplace=True)\n",
    "    importance_df['mean'].plot(kind='barh', color='b', alpha=0.25, xerr=importance_df['std'], error_kw={'ecolor': 'r'})\n",
    "    if save_fig:\n",
    "        plt.savefig(output_path) \n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c197f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_imp (MDI) 확인\n",
    "# 앞서 계산한 MDI 결과 변수인 feat_imp를 넣습니다.\n",
    "plot_feature_importance(feat_imp)\n",
    "\n",
    "# feat_imp_mda (MDA) 확인\n",
    "# 앞서 계산한 MDA 결과 변수인 feat_imp_mda를 넣습니다.\n",
    "plot_feature_importance(feat_imp_mda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d914cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFE CV, Recursive Feature Elimination\n",
    "# kernel='linear'여야 coef_ 속성을 통해 특성 중요도를 파악할 수 있습니다.\n",
    "svc_rbf = SVC(kernel='linear', probability=True) \n",
    "\n",
    "# RFECV 인스턴스 생성\n",
    "# step=1: 한 번에 하나씩 특성을 제거\n",
    "# cv=5: 5-Fold 교차 검증 사용\n",
    "# scoring='accuracy': 정확도를 기준으로 성능 평가\n",
    "rfe_cv = RFECV(estimator=svc_rbf, step=1, cv=5, scoring='accuracy') \n",
    "\n",
    "# fit: 학습 진행 (X_sc: 스케일링된 특성 데이터, y: 라벨)\n",
    "rfe_fitted = rfe_cv.fit(X_sc, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddb047f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선택된 피쳐 확인하기\n",
    "\n",
    "# support_ 속성을 사용하여 선택된 특성(True)의 컬럼명만 추출\n",
    "selected_features = X_sc.columns[rfe_fitted.support_]\n",
    "\n",
    "# 결과 출력\n",
    "print(\"Optimal number of features : %d\" % rfe_fitted.n_features_)\n",
    "print(\"Selected features :\", selected_features.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a683ce67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SFS, Sequential Feature Selection\n",
    "\n",
    "n = 2 \n",
    "sfs_forward = SequentialFeatureSelector(svc_rbf, n_features_to_select=n, direction='forward')\n",
    "sfs_fitted = sfs_forward.fit(X_sc, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8764c1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선택된 피쳐 확인하기\n",
    "\n",
    "# support_는 선택된 특성을 True로 표시하는 불리언 배열입니다.\n",
    "sfs_features = X_sc.columns[sfs_fitted.support_]\n",
    "\n",
    "print(\"Selected features by SFS:\", sfs_features.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12504443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q. 코드를 작성해주세요\n",
    "!pip install\n",
    "# SHAP, Shapley Additive explanations\n",
    "import shap\n",
    "explainer = shap.TreeExplainer(rfc)\n",
    "shap_value = explainer.shap_values(X_sc)\n",
    "\n",
    "# shap_value, X_sc 사용 shap.summary_plot 그리기\n",
    "shap.summary_plot(shap_value, X_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72a7109",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import io\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ta\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score, roc_auc_score, roc_curve\n",
    "\n",
    "sys.path.append('/aiffel/aiffel/fnguide/data/')\n",
    "from libs.mlutil.pkfold import PKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e2acaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 경로 설정 및 pickle 파일 불러오기\n",
    "DATA_PATH = '/aiffel/aiffel/fnguide/data/'\n",
    "data_file_name = os.path.join(DATA_PATH, 'sub_upbit_eth_min_feature_labels.pkl')\n",
    "\n",
    "\n",
    "# 여기서부터 모델에 적용하기 위한 데이터 정제화를 시작합니다.\n",
    "df_data['t_value'].value_counts()\n",
    "\n",
    "# 데이터셋 비율 나누기\n",
    "train_ratio, test_ratio = 0.7, 0.2\n",
    "n_train = int(np.round(len(df_data) * train_ratio))\n",
    "n_test = int(np.round(len(df_data) * test_ratio))\n",
    "\n",
    "X, y = df_data.iloc[:, 5:-1], df_data.iloc[:, -1]\n",
    "\n",
    "# standardzation\n",
    "sc = StandardScaler()\n",
    "X_sc = sc.fit_transform(X)\n",
    "\n",
    "# 데이터셋 분리\n",
    "train_x, test_x, train_y, test_y = X_sc[:n_train, :], X_sc[-n_test:, :], y.iloc[:n_train], y.iloc[-n_test:]\n",
    "\n",
    "train_x = pd.DataFrame(train_x, index=train_y.index, columns=X.columns)\n",
    "train_y = pd.Series(train_y, index=train_y.index)\n",
    "test_x = pd.DataFrame(test_x, index=test_y.index, columns=X.columns)\n",
    "test_y = pd.Series(test_y, index=test_y.index)\n",
    "\n",
    "# 학습 시간 단축을 위해 여기선 편의상 1000개의 데이터만 가져옵니다.\n",
    "train_x = train_x[:1000] # 데이터셋을 증가 혹은 감소시켜 결과를 비교해봅시다.\n",
    "train_y = train_y[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c50909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q. 코드를 작성해주세요\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "class PurgedKFold(KFold):\n",
    "    \"\"\"\n",
    "    K-Fold를 확장하여 시계열 데이터의 정보 유출(Leakage)을 방지하는 클래스입니다.\n",
    "    - Purging: 테스트 기간과 겹치는(Label이 겹치는) 훈련 데이터를 제거합니다.\n",
    "    - Embargo: 테스트 기간 직후의 훈련 데이터를 일정 기간 제외합니다.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_splits=3, t1=None, pctEmbargo=0.):\n",
    "        # 시계열이므로 shuffle=False로 고정합니다.\n",
    "        super(PurgedKFold, self).__init__(n_splits, shuffle=False, random_state=None)\n",
    "        self.t1 = t1\n",
    "        self.pctEmbargo = pctEmbargo\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        indices = np.arange(X.shape[0])\n",
    "        mbrg = int(X.shape[0] * self.pctEmbargo)\n",
    "        \n",
    "        for train_ix, test_ix in super(PurgedKFold, self).split(X):\n",
    "            # 1. Purging (기본적으로 테스트셋 시간대 전후의 중첩 구간 제거)\n",
    "            # 여기서는 t1(이벤트 종료 시점) 정보를 활용하여 \n",
    "            # 훈련 데이터 중 라벨이 테스트 데이터 시점과 겹치는 부분을 찾아서 제외합니다.\n",
    "            \n",
    "            # 테스트 셋의 시작과 끝 시간 찾기\n",
    "            t0 = self.t1.index[train_ix] # 훈련 데이터의 시작 시간들\n",
    "            test_start_time = self.t1.index[test_ix[0]]\n",
    "            test_end_time = self.t1.index[test_ix[-1]]\n",
    "\n",
    "            # 훈련 셋에서 제외해야 할 인덱스 찾기 (Overlap)\n",
    "            # t1(이벤트 종료)이 테스트 시작보다 뒤에 있는 경우 (미래 정보 포함)\n",
    "            train_t1 = self.t1.iloc[train_ix]\n",
    "            # 테스트 구간과 겹치는 훈련 데이터 제거\n",
    "            train_ix = train_ix[train_t1 <= test_start_time] \n",
    "            \n",
    "            # 2. Embargo (테스트셋 뒤의 훈련 데이터 일부 제거)\n",
    "            # 테스트셋 인덱스 중 가장 큰 값 + 엠바고 크기보다 큰 훈련 인덱스만 남김\n",
    "            max_test_ix = test_ix.max()\n",
    "            train_ix = train_ix[~((train_ix > max_test_ix) & (train_ix <= max_test_ix + mbrg))]\n",
    "            \n",
    "            yield train_ix, test_ix\n",
    "\n",
    "n_cv = 5\n",
    "\n",
    "# t1: 이벤트(라벨) 종료 시점 정보\n",
    "# (train_y의 인덱스가 datetime인 경우를 가정합니다)\n",
    "t1 = pd.Series(train_y.index.values, index=train_y.index)\n",
    "\n",
    "# Purged K-Fold 객체 생성\n",
    "# 이제 위에서 정의했으므로 오류가 나지 않습니다.\n",
    "cv = PurgedKFold(n_splits=n_cv, t1=t1, pctEmbargo=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed19692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridsearchCV에서 사용할 파라미터 설정합니다. 파라미터값을 바꿔보세요\n",
    "bc_params = {'n_estimators': [5, 10, 20],\n",
    "             'max_features': [0.5, 0.7],\n",
    "             'base_estimator__max_depth': [3,5,10,20],\n",
    "             'base_estimator__max_features': [None, 'auto'],\n",
    "             'base_estimator__min_samples_leaf': [3, 5, 10],\n",
    "             'bootstrap_features': [False, True]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cb52f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest 사용\n",
    "rfc = RandomForestClassifier(class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598a1e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Q. 코드를 작성해주세요\n",
    "\n",
    "# Bagging 적용\n",
    "# rfc(RandomForest)를 기본 모델(base_estimator)로 사용하는 배깅 분류기를 만듭니다.\n",
    "# n_jobs=-1을 사용하여 가능한 모든 CPU 코어를 사용하여 속도를 높입니다.\n",
    "bag_rfc = BaggingClassifier(base_estimator=rfc, n_jobs=-1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21364a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Q. 코드를 작성해주세요\n",
    "\n",
    "# GridSearchCV 적용\n",
    "# estimator: 앞서 정의한 BaggingClassifier 객체 (bag_rfc)\n",
    "# param_grid: 탐색할 파라미터 조합 (bc_params)\n",
    "# cv: 정보 유출을 막는 Purged K-Fold 객체 (cv)\n",
    "# scoring: 성능 평가 기준 (예: 'accuracy', 'f1_macro' 등)\n",
    "# verbose: 진행 상황 출력 (1 이상이면 로그 출력)\n",
    "gs_rfc = GridSearchCV(estimator=bag_rfc, param_grid=bc_params, cv=cv, scoring='accuracy', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6b1711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit\n",
    "gs_rfc.fit(train_x, train_y)\n",
    "\n",
    "# best estimator \n",
    "gs_rfc_best = gs_rfc.best_estimator_\n",
    "gs_rfc_best.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62100b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측값 확인\n",
    "pred_y = gs_rfc_best.predict(test_x)\n",
    "prob_y = gs_rfc_best.predict_proba(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987a76ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q. 코드를 작성해주세요\n",
    "\n",
    "# test_y, pred_y를 활용한 지표 적용\n",
    "confusion = confusion_matrix(test_y, pred_y)\n",
    "accuracy  = accuracy_score(test_y, pred_y)\n",
    "precision = precision_score(test_y, pred_y)\n",
    "recall    = recall_score(test_y, pred_y)\n",
    "\n",
    "# 지표를 통한 결과 확인\n",
    "print('================= confusion matrix ====================')\n",
    "print(confusion)\n",
    "print('=======================================================')\n",
    "print(f'정확도:{accuracy:.4f}, 정밀도:{precision:.4f}, 재현율:{recall:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e23064",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- 확률 및 예측값 생성 ---\n",
    "pred_proba_class1 = gs_rfc_best.predict_proba(test_x)[:, 1]\n",
    "pred_y = gs_rfc_best.predict(test_x)\n",
    "# --------------------------------------\n",
    "\n",
    "# Q. 코드를 작성해주세요\n",
    "\n",
    "# test_y, pred_y를 활용한 지표 적용\n",
    "confusion = confusion_matrix(test_y, pred_y)\n",
    "accuracy  = accuracy_score(test_y, pred_y)\n",
    "precision = precision_score(test_y, pred_y)\n",
    "recall    = recall_score(test_y, pred_y)\n",
    "\n",
    "# 지표를 통한 결과 확인\n",
    "print('================= confusion matrix ====================')\n",
    "print(confusion)\n",
    "print('=======================================================')\n",
    "print(f'정확도:{accuracy:.4f}, 정밀도:{precision:.4f}, 재현율:{recall:.4f}')\n",
    "\n",
    "\n",
    "# Q. 코드를 작성해주세요\n",
    "\n",
    "# ROC curve 만들기\n",
    "fpr, tpr, thresholds = roc_curve(test_y, pred_proba_class1)\n",
    "auc_score = auc(fpr, tpr) # 변수명 중복 방지를 위해 auc -> auc_score로 변경 권장\n",
    "\n",
    "# ROC curve 시각화\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, linewidth=2, label=f'ROC Curve (AUC = {auc_score:.4f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--') # dashed diagonal\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.title('ROC Curve')\n",
    "print(f'auc:{auc_score:.4f}')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
